{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeuZd7YzHT-t",
    "outputId": "8e3b01c6-e3dc-4ef8-dac3-282218176277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'F5-TTS'...\n",
      "remote: Enumerating objects: 2128, done.\u001b[K\n",
      "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
      "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
      "remote: Total 2128 (delta 106), reused 150 (delta 86), pack-reused 1942 (from 1)\u001b[K\n",
      "Receiving objects: 100% (2128/2128), 1.81 MiB | 1.10 MiB/s, done.\n",
      "Resolving deltas: 100% (1304/1304), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SWivid/F5-TTS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM9Q0i29HT76",
    "outputId": "dcb2a14c-b03a-4de4-f28e-ef82b620a831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/f5tts/F5-TTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/f5tts/env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd F5-TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egIZy_6PHT5n"
   },
   "outputs": [],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMDq_SJIH6hL"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9DMnhcdHT3Q",
    "outputId": "038c3fa9-1135-4cbb-d247-e75da5c0cdb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.217 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Word segmentation module jieba initialized.\n",
      "\n",
      "Download Vocos from huggingface charactr/vocos-mel-24khz\n",
      "config.yaml: 100%|█████████████████████████████| 461/461 [00:00<00:00, 2.45MB/s]\n",
      "pytorch_model.bin: 100%|███████████████████| 54.4M/54.4M [00:13<00:00, 3.97MB/s]\n",
      "model_1200000.safetensors: 100%|███████████| 1.35G/1.35G [07:21<00:00, 3.06MB/s]\n",
      "Using F5-TTS...\n",
      "\n",
      "vocab :  /mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/F5-TTS/src/f5_tts/infer/examples/vocab.txt\n",
      "token :  custom\n",
      "model :  /home/kingdom/.cache/huggingface/hub/models--SWivid--F5-TTS/snapshots/4dcc16f297f2ff98a17b3726b16f5de5a5e45672/F5TTS_Base/model_1200000.safetensors \n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/bin/f5-tts_infer-cli\", line 5, in <module>\n",
      "    from f5_tts.infer.infer_cli import main\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/F5-TTS/src/f5_tts/infer/infer_cli.py\", line 163, in <module>\n",
      "    ema_model = load_model(model_cls, model_cfg, ckpt_file, mel_spec_type=mel_spec_type, vocab_file=vocab_file)\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/F5-TTS/src/f5_tts/infer/utils_infer.py\", line 259, in load_model\n",
      "    model = load_checkpoint(model, ckpt_path, device, dtype=dtype, use_ema=use_ema)\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/F5-TTS/src/f5_tts/infer/utils_infer.py\", line 190, in load_checkpoint\n",
      "    checkpoint = load_file(ckpt_path, device=device)\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/safetensors/torch.py\", line 315, in load_file\n",
      "    result[k] = f.get_tensor(k)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.95 GiB of which 15.50 MiB is free. Including non-PyTorch memory, this process has 1.93 GiB memory in use. Of the allocated memory 1.89 GiB is allocated by PyTorch, and 11.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!f5-tts_infer-cli \\\n",
    "--model \"F5-TTS\" \\\n",
    "--ref_audio \"../PRB_Nep_01_Bhojpur_01.wav\" \\\n",
    "--ref_text \"नमस्ते साथीहरू आज हामी भोजपुर जिल्लाको यात्रामा निस्किएका छौं\" \\\n",
    "--gen_text \"Hello friends Today we are embarking on a journey to Bhojpur District\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EEHC6R-aICHN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torchaudio/_internal/__init__.py\", line 2, in <module>\n",
      "    from .fb import download_url_to_file, load_state_dict_from_url\n",
      "ModuleNotFoundError: No module named 'torchaudio._internal.fb'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/bin/f5-tts_infer-gradio\", line 5, in <module>\n",
      "    from f5_tts.infer.infer_gradio import main\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/F5-TTS/src/f5_tts/infer/infer_gradio.py\", line 13, in <module>\n",
      "    import torchaudio\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torchaudio/__init__.py\", line 2, in <module>\n",
      "    from . import _extension  # noqa  # usort: skip\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torchaudio/_extension/__init__.py\", line 5, in <module>\n",
      "    from torchaudio._internal.module_utils import fail_with_message, is_module_available, no_op\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torchaudio/_internal/__init__.py\", line 4, in <module>\n",
      "    from torch.hub import download_url_to_file, load_state_dict_from_url\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torch/__init__.py\", line 2016, in <module>\n",
      "    from torch import _VF as _VF, functional as functional  # usort: skip\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torch/nn/__init__.py\", line 8, in <module>\n",
      "    from torch.nn.modules import *  # usort: skip # noqa: F403\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 1, in <module>\n",
      "    from .module import Module  # usort: skip\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 29, in <module>\n",
      "    from torch.utils._python_dispatch import is_traceable_wrapper_subclass\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torch/utils/_python_dispatch.py\", line 12, in <module>\n",
      "    import torchgen.model\n",
      "  File \"/mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/lib/python3.10/site-packages/torchgen/model.py\", line 2590, in <module>\n",
      "    class OperatorName:\n",
      "  File \"/usr/lib/python3.10/dataclasses.py\", line 1175, in wrap\n",
      "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
      "  File \"/usr/lib/python3.10/dataclasses.py\", line 1075, in _process_class\n",
      "    for fn in _frozen_get_del_attr(cls, field_list, globals):\n",
      "  File \"/usr/lib/python3.10/dataclasses.py\", line 613, in _frozen_get_del_attr\n",
      "    _create_fn('__delattr__',\n",
      "  File \"/usr/lib/python3.10/dataclasses.py\", line 432, in _create_fn\n",
      "    exec(txt, globals, ns)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!f5-tts_infer-gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/f5tts/env/bin/f5-tts_infer-cli: /mnt/45b9faff-45f3-43f2-903f-9b92a9a6338c/major-project/notebooks/tts/env/bin/python: bad interpreter: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!f5-tts_infer-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpts  data  Dockerfile  LICENSE  pyproject.toml  README.md  ruff.toml\tsrc\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
